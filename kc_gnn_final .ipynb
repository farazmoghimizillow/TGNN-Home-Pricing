{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0468d270-f5f7-47a9-bff5-8863cd82dc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nKNN based (n=200) graph distance +numeric edge feat , train end date change + bigger training data\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version='kc_gnn_16'\n",
    "\n",
    "\n",
    "'''\n",
    "KNN based (n=200) graph distance +numeric edge feat , train end date change + bigger training data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae23592-808d-4319-93da-00e4f2d859a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.6\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import collections\n",
    "import copy\n",
    "import csv\n",
    "import math\n",
    "import numbers\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "import types\n",
    "import warnings\n",
    "from functools import partial, update_wrapper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader, NeighborLoader, NeighborSampler\n",
    "from torch_geometric.nn import SAGEConv, TransformerConv,NNConv\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from tqdm import tqdm\n",
    "import torch_geometric\n",
    "torch_geometric.__version__\n",
    "torch.__version__\n",
    "print(torch.version.cuda)\n",
    "import sys\n",
    "# sys.path\n",
    "# sys.path.append('zestimate-neural-net')\n",
    "# from pyspark import SparkContext, SparkConf\n",
    "# from pyspark.sql import DataFrame, SparkSession\n",
    "# from pyspark.sql import functions as F\n",
    "# from pyspark.sql import types as T\n",
    "# from pyspark.sql.window import Window\n",
    "\n",
    "# from aip_spark_sdk import AwsHelper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import copy\n",
    "import csv\n",
    "import math\n",
    "# import numbers\n",
    "# import random\n",
    "# import threading\n",
    "# import time\n",
    "# import types\n",
    "import warnings\n",
    "from functools import partial, update_wrapper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "# from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import BallTree\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d56caba-1914-41f1-bc1c-cb1036d3694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_dict():\n",
    "    num_features = [\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"year_built\",\n",
    "        \"year_reno\",\n",
    "        \"grade\",\n",
    "        \"fbsmt_grade\",\n",
    "        \"condition\",\n",
    "        \"stories\",\n",
    "        \"beds\",\n",
    "        \"bath_full\",\n",
    "        \"bath_3qtr\",\n",
    "        \"bath_half\",\n",
    "    ]\n",
    "    num_log_features = [\n",
    "        \"land_val\",\n",
    "        \"imp_val\",\n",
    "        \"sqft_lot\",\n",
    "        \"sqft\",\n",
    "        \"sqft_1\",\n",
    "        \"sqft_fbsmt\",\n",
    "        \"garb_sqft\",\n",
    "        \"gara_sqft\",\n",
    "    ]\n",
    "    cat_features = [\n",
    "        # \"area\",\n",
    "        \"city\",\n",
    "       \"submarket\",\n",
    "        \"zoning\",\n",
    "        # \"present_use\",\n",
    "\n",
    "        # \"wfnt\",\n",
    "        # \"golf\",\n",
    "        # \"greenbelt\",\n",
    "        # \"noise_traffic\",\n",
    "        # \"view_rainier\",\n",
    "        # \"view_olympics\",\n",
    "        # \"view_cascades\",\n",
    "        # \"view_territorial\",\n",
    "        # \"view_skyline\",\n",
    "        # \"view_sound\",\n",
    "        # \"view_lakewash\",\n",
    "        # \"view_lakesamm\",\n",
    "        # \"view_otherwater\",\n",
    "        # \"view_other\",\n",
    "        \n",
    "        # \"sale_date_yyyymm\",\n",
    "        # \"sale_decade\",\n",
    "        # \"sale_year\",\n",
    "        # \"sale_week\",\n",
    "    ]\n",
    "    ord_features = [\n",
    "        # \"stories\",\n",
    "        # \"beds\",\n",
    "        # \"bath_full\",\n",
    "        # \"bath_3qtr\",\n",
    "        # \"bath_half\",\n",
    "    ]\n",
    "    time_features = [\"sale_date\",]\n",
    "\n",
    "    feature_dict = {\n",
    "        \"nums\": num_features,\n",
    "        \"num_logs\": num_log_features,\n",
    "        \"cats\": cat_features,\n",
    "        \"ords\": ord_features,\n",
    "        \"time\": time_features,\n",
    "    }\n",
    "\n",
    "    return feature_dict\n",
    "\n",
    "\n",
    "feature_dict = get_feature_dict()\n",
    "\n",
    "id_cols = [\"sale_id\", \"pinx\", \"submarket\"]\n",
    "response_col = \"sale_price\"\n",
    "feature_cols = set(\n",
    "    feature_dict[\"nums\"] +\n",
    "    feature_dict[\"num_logs\"] +\n",
    "    feature_dict[\"cats\"] +\n",
    "    feature_dict[\"ords\"] +\n",
    "    feature_dict[\"time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2653049b-862d-42fe-a2fd-62e659ce989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('kingcountysales.csv')\n",
    "df[\"sale_date\"]=pd.to_datetime(df[\"sale_date\"])\n",
    "max_train_date = \"2021-01-01\"\n",
    "min_train_date = \"2016-01-01\"\n",
    "sample_beg_date= \"2015-01-01\"\n",
    "df_1= df[df[\"sale_date\"] >= min_train_date].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c71a07d-fe13-4ef9-9577-25f40bd5288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseTransformer:\n",
    "    \"\"\"Response transformer.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.median = None\n",
    "\n",
    "    def fit(self, y):\n",
    "        y_trans = np.log1p(y)\n",
    "        self.median = np.median(y_trans)\n",
    "        return self\n",
    "\n",
    "    def transform(self, y):\n",
    "        y = np.log1p(y) - self.median\n",
    "        return y\n",
    "\n",
    "    def fit_transform(self, y):\n",
    "        return self.fit(y).transform(y)\n",
    "\n",
    "    def inverse_transform(self, y):\n",
    "        y = np.expm1(y + self.median)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a86b4b-4b00-4c16-a46b-7cdb7b325025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_missing(df):\n",
    "    df = (\n",
    "        df\n",
    "        .assign(imp_val=lambda x: x['imp_val'].replace(0, np.nan))\n",
    "        .assign(land_val=lambda x: x['land_val'].replace(0, np.nan))\n",
    "        .assign(sqft=lambda x: x['sqft'].replace(0, np.nan))\n",
    "        .assign(beds=lambda x: x['beds'].replace(54, np.nan))\n",
    "    )\n",
    "    return df\n",
    "def clean_sqft(df):\n",
    "    sqft_1 = df.query('sqft < sqft_1')['sqft_1']\n",
    "    sqft_fbsmt = df.query('sqft < sqft_1')['sqft_fbsmt']\n",
    "    df.loc[df['sqft'] < df['sqft_1'], 'sqft'] = sqft_1 + sqft_fbsmt\n",
    "    return df\n",
    "\n",
    "def clean_year_built(df):\n",
    "    df['build_type'] = 'Standard'\n",
    "    df.loc[(df['year_built'] - 1) == pd.to_datetime(df['sale_date']).dt.year, 'build_type'] = 'New Construction'\n",
    "    df.loc[(df['year_built'] - 1) > pd.to_datetime(df['sale_date']).dt.year, 'build_type'] = 'Lot Sale'\n",
    "    return df\n",
    "\n",
    "def prepare_outliers(df):\n",
    "    df = (\n",
    "        df\n",
    "        .pipe(clean_sqft)\n",
    "        .pipe(clean_year_built)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def preprocessor(df_1, feature_c):\n",
    "    df_out=df_1.copy()\n",
    "    # feature_cols=feature_c.copy()\n",
    "    \n",
    "    '''\n",
    "    categorical features: replace each category with its price statistics from prior years  \n",
    "    '''\n",
    "    df_sample=  df[(df[\"sale_date\"] < min_train_date) & (df[\"sale_date\"] >= sample_beg_date)].copy()\n",
    "    trans_1=ResponseTransformer()\n",
    "    df_sample[response_col]=trans_1.fit_transform(df_sample[response_col].values)\n",
    "    # df_sample[response_col]= np.log1p(df_sample[response_col].values) - df_sample[response_col].median()\n",
    "    for cat_col in feature_dict['cats']:\n",
    "        cat_stats= df_sample[[cat_col,response_col]].groupby(cat_col).describe().add_prefix(f'{cat_col}_')[f'{cat_col}_sale_price'].reset_index()\n",
    "        df_out=df_out.merge(cat_stats, how='left', on=cat_col)\n",
    "        print(cat_col)\n",
    "        print(df_out.shape)\n",
    "        print(df_out['sale_date'].isna().sum())\n",
    "        df_out.drop(columns=cat_col, inplace=True)\n",
    "        feature_cols.update(list(cat_stats.columns))\n",
    "        feature_cols.remove(cat_col)\n",
    "        \n",
    "    '''\n",
    "    temporal adjusting \n",
    "    '''\n",
    "    print(df_out['sale_date'].isna().sum())\n",
    "    date_time = df_out['sale_date']\n",
    "\n",
    "    timestamp_s = date_time.dt.week\n",
    "    # df_1['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "    # df_1['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "    df_out['year_sin'] = np.sin(timestamp_s * (2 * np.pi / 52))\n",
    "    df_out['year_cos'] = np.cos(timestamp_s * (2 * np.pi / 52))\n",
    "    # df_out.drop(columns='sale_date', inplace=True)\n",
    "    df_out['trans_year']=date_time.dt.year\n",
    "    feature_cols.update(['trans_year','year_sin','year_cos'])\n",
    "    feature_cols.remove('sale_date')\n",
    "    \n",
    "    '''\n",
    "    taking log\n",
    "    '''\n",
    "    \n",
    "    df_out[feature_dict['num_logs']]=np.log1p(df_out[feature_dict['num_logs']])\n",
    "    '''\n",
    "    filling missing values\n",
    "    '''\n",
    "    \n",
    "    df_out.fillna(df_out.median(), inplace=True)\n",
    "    # print(df_out.isna().sum())\n",
    "    # df_out.dropna(inplace=True)\n",
    "    return df_out, feature_cols\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "253f8a3d-dbfb-4d6b-a6f7-b2a2507fd16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city\n",
      "(161512, 56)\n",
      "0\n",
      "submarket\n",
      "(161512, 63)\n",
      "0\n",
      "zoning\n",
      "(161512, 70)\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_675/1722977719.py:57: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  timestamp_s = date_time.dt.week\n",
      "/tmp/ipykernel_675/1722977719.py:76: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_out.fillna(df_out.median(), inplace=True)\n",
      "/tmp/ipykernel_675/1722977719.py:76: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df_out.fillna(df_out.median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "feature_cols = set(\n",
    "    feature_dict[\"nums\"] +\n",
    "    feature_dict[\"num_logs\"] +\n",
    "    feature_dict[\"cats\"] +\n",
    "    feature_dict[\"ords\"] +\n",
    "    feature_dict[\"time\"]\n",
    ")\n",
    "old_feat_col=feature_cols.copy()\n",
    "df_1=prepare_missing(df_1)\n",
    "df_1=prepare_outliers(df_1)\n",
    "df_out,feature_cols_2=preprocessor(df_1, feature_cols)\n",
    "df_out[\"sale_year\"] = df_out[\"sale_date\"].dt.year\n",
    "df_out[\"sale_month\"] = df_out[\"sale_date\"].dt.month\n",
    "df_out[\"sale_week\"] = df_out[\"sale_date\"].dt.isocalendar().week\n",
    "df_out[\"sale_day\"] = df_out[\"sale_date\"].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1303fe6-458a-4c3b-85f1-a86118c5c7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out['beds'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a9929e4-3504-4a17-95ce-7b3c70ece451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_675/2730997172.py:13: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  X_train=df_train[feature_cols].copy()\n",
      "/tmp/ipykernel_675/2730997172.py:16: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  X_test=df_test[feature_cols].copy()\n"
     ]
    }
   ],
   "source": [
    "df_train = df_out[(df_out[\"sale_date\"] < max_train_date) & (df_out[\"sale_date\"] >= min_train_date)].copy()\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_out[df_out[\"sale_date\"] >= max_train_date].copy()\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "response_transformer = ResponseTransformer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train=df_train[feature_cols].copy()\n",
    "y_train=response_transformer.fit_transform(df_train[response_col])\n",
    "\n",
    "X_test=df_test[feature_cols].copy()\n",
    "y_test=df_test[response_col].copy()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train[list(X_train.columns)]=scaler.fit_transform(X_train)\n",
    "X_test[list(X_test.columns)]=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0691deb-e0ba-4bf6-806c-1c39c066ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_percentage_error(true, pred, epsilon=1e-6):\n",
    "    \"\"\"Mean Percentage Error (MPE).\"\"\"\n",
    "    pe = (pred - true) / (true + epsilon)\n",
    "    return np.mean(pe)\n",
    "\n",
    "\n",
    "def median_absolute_percentage_error(true, pred, epsilon=1e-6):\n",
    "    \"\"\"Median Absolute Percentage Error (MdAPE).\"\"\"\n",
    "    ape = np.abs(pred - true) / (true + epsilon)\n",
    "    return np.median(ape)\n",
    "\n",
    "\n",
    "def median_percentage_error(true, pred, epsilon=1e-6):\n",
    "    \"\"\"Median Percentage Error (MdPE).\"\"\"\n",
    "    pe = (pred - true) / (true + epsilon)\n",
    "    return np.median(pe)\n",
    "\n",
    "\n",
    "def frac_within_ci(true, pred_low, pred_high):\n",
    "    \"\"\"Fraction within Confidence Interval.\"\"\"\n",
    "    wci = (true >= pred_low) & (true <= pred_high)\n",
    "    return np.mean(wci)\n",
    "\n",
    "\n",
    "def mean_ci_width(true, pred_low, pred_high, epsilon=1e-6):\n",
    "    \"\"\"Mean Confidence Interval Width.\"\"\"\n",
    "    ciw = (pred_high - pred_low) / (true + epsilon)\n",
    "    return np.mean(ciw)\n",
    "\n",
    "\n",
    "def median_ci_width(true, pred_low, pred_high, epsilon=1e-6):\n",
    "    \"\"\"Median Confidence Interval Width.\"\"\"\n",
    "    ciw = (pred_high - pred_low) / (true + epsilon)\n",
    "    return np.median(ciw)\n",
    "\n",
    "\n",
    "def evaluate_preds(y_test, y_pred, y_pred_low=None, y_pred_high=None):\n",
    "    output = {}\n",
    "    output[\"Count\"] = len(y_test)\n",
    "    output[\"R2\"] = r2_score(y_test, y_pred)\n",
    "    output[\"MAE\"] = mean_absolute_error(y_test, y_pred)\n",
    "    output[\"MdAE\"] = median_absolute_error(y_test, y_pred)\n",
    "    output[\"MPE\"] = mean_percentage_error(y_test, y_pred)\n",
    "    output[\"MdPE\"] = median_percentage_error(y_test, y_pred)\n",
    "    output[\"MAPE\"] = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    output[\"MdAPE\"] = median_absolute_percentage_error(y_test, y_pred)\n",
    "    if y_pred_low is not None and y_pred_high is not None:\n",
    "        output[\"Pct. Within CI\"] = frac_within_ci(y_test, y_pred_low, y_pred_high)\n",
    "        output[\"Mean CI Width\"] = mean_ci_width(y_test, y_pred_low, y_pred_high)\n",
    "        output[\"Med. CI Width\"] = median_ci_width(y_test, y_pred_low, y_pred_high)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7479217d-095b-49ee-ad46-4c19efaf0b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmostly referencing Reid's public notebook on kaggle for typical preprocessing steps \\nhttps://www.kaggle.com/code/reidjohnson/house-price-eda-and-modeling-with-python\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "mostly referencing Reid's public notebook on kaggle for typical preprocessing steps \n",
    "https://www.kaggle.com/code/reidjohnson/house-price-eda-and-modeling-with-python\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d5d7292-2a4f-4b37-9c16-8afb4aab14b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "771c75d5-fe35-43b7-8856-db2d9d3764ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime=pd.concat([df_train, df_test])['sale_date']\n",
    "# min_date= datetime.min()\n",
    "# t=datetime-min_date\n",
    "# t=t.dt.days\n",
    "    \n",
    "# idx=torch.arange(len(df_train)+len(df_test))    \n",
    "    \n",
    "# time_edge= edge_index.clone()\n",
    "\n",
    "# '''\n",
    "# fixing the time leakage: basically removing all links that go from future to past\n",
    "# '''\n",
    "\n",
    "# t_dic=dict(zip(idx.numpy(), t.values))\n",
    "# a=time_edge[0].apply_(t_dic.get)\n",
    "# b=time_edge[1].apply_(t_dic.get)\n",
    "# c=b-a\n",
    "# new_edge=torch.cat((edge_index,torch.unsqueeze(c,0)),0)\n",
    "# new_edge=new_edge[:,new_edge[2]>0]\n",
    "# # new_edge=new_edge[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "079d55ed-57bb-4907-a8f8-6d6c12c6ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchStandardScaler:\n",
    "    def fit(self, x):\n",
    "        self.mean = x.mean(0, keepdim=True)\n",
    "        self.std = x.std(0, unbiased=False, keepdim=True)\n",
    "    def transform(self, x):\n",
    "        x -= self.mean\n",
    "        x /= (self.std + 1e-7)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f01d7c6-9979-4d74-ae0e-710280299f45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16160474])\n",
      "torch.Size([2, 7756285])\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data.datapipes import functional_transform\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from torch_geometric.utils import scatter\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# assert X_train.isin([np.inf, -np.inf]).any().any() == False\n",
    "# assert X_test.isin([np.inf, -np.inf]).any().any() == False\n",
    "\n",
    "\n",
    "\n",
    "data_x = torch.Tensor(pd.concat([X_train, X_test]).values)\n",
    "data_y = torch.Tensor(pd.concat([y_train, y_test]).values).reshape(-1, 1)\n",
    "train_idx = torch.arange(len(X_train))\n",
    "idx=torch.arange(len(X_train)+len(X_test))\n",
    "\n",
    "\n",
    "'''\n",
    "getting the relative days since begining for each node. \n",
    "'''\n",
    "\n",
    "datetime=pd.concat([df_train, df_test]).reset_index()['sale_date']\n",
    "min_date= datetime.min()\n",
    "t=datetime-min_date\n",
    "t=t.dt.days\n",
    "    \n",
    "\n",
    "data = Data(x=data_x, y=data_y)\n",
    "data.train_mask = torch.tensor(np.isin(np.arange(len(data_x)), train_idx), dtype=torch.bool)\n",
    "\n",
    "\n",
    "'''\n",
    "get coordinates and put as the data.pos, pyg uses this for graph creation\n",
    "'''\n",
    "\n",
    "lat_long=pd.concat([df_train, df_test]).reset_index(drop=True)[['latitude', 'longitude']]\n",
    "\n",
    "latitude=lat_long['latitude'].values\n",
    "longitude=lat_long['longitude'].values\n",
    "latitude = latitude * (math.pi / 180.)\n",
    "longitude = longitude * (math.pi / 180.)\n",
    "\n",
    "R = 6371  # approximate Earth radius in km\n",
    "x = R * np.cos(latitude) * np.cos(longitude)\n",
    "y = R * np.cos(latitude) * np.sin(longitude)\n",
    "z = R * np.sin(latitude)\n",
    "data.pos= torch.Tensor(np.stack((x, y,z), axis=1))\n",
    "\n",
    "\n",
    "edge_transform= T.KNNGraph(k=100,force_undirected=False)\n",
    "data= edge_transform(data)\n",
    "\n",
    "\n",
    "\n",
    "# radius_transform=T.RadiusGraph(max_num_neighbors=200,r=0.5)\n",
    "# data=radius_transform(data)\n",
    "\n",
    "'''\n",
    "removing leaky radius\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "idx=torch.arange(len(df_train)+len(df_test))    \n",
    "    \n",
    "time_edge= data.edge_index.clone()\n",
    "print(time_edge.shape)\n",
    "\n",
    "'''\n",
    "fixing the time leakage: basically removing all links that go from future to past\n",
    "'''\n",
    "\n",
    "t_dic=dict(zip(idx.numpy(), t.values))\n",
    "a=time_edge[0].apply_(t_dic.get)\n",
    "b=time_edge[1].apply_(t_dic.get)\n",
    "c=b-a\n",
    "new_edge=torch.cat((data.edge_index,torch.unsqueeze(c,0)),0)\n",
    "new_edge_1=new_edge[:,new_edge[2]>0]\n",
    "new_edge=new_edge_1[:2]\n",
    "print(new_edge.shape)\n",
    "\n",
    "data.edge_index=new_edge\n",
    "'''\n",
    "getting the initial edge index produced by knn\n",
    "'''\n",
    "\n",
    "# transform= T.Cartesian()\n",
    "# data= transform(data)  # adding the cartesian coordinates as an edge feature\n",
    "\n",
    "edge_index=data.edge_index\n",
    "\n",
    "def add_edge_feature(data,add_distance=True, add_time= True, add_y=False, y_scaling=False,tot_scaling=False, differential_cols=None):\n",
    "    src, dst = data.edge_index\n",
    "    # new_edge_attr=data.edge_attr\n",
    "    if add_distance==True:\n",
    "        eu_distance_transform=T.Distance(norm=True) \n",
    "        print('ditsance added')\n",
    "        data= eu_distance_transform(data) #adding euclidean distance (km) as an edge feature \n",
    "    new_edge_attr=data.edge_attr\n",
    "    if add_time==True:\n",
    "        new_edge_attr=torch.cat([new_edge_attr, new_edge_1[2].type(torch.FloatTensor).unsqueeze(dim=1)], dim=1)\n",
    "        print('time added')\n",
    "        print(new_edge_attr.shape)\n",
    "    if add_y==True:\n",
    "        y_edge_attr=data.y[src]\n",
    "        if y_scaling==True:\n",
    "            foo = TorchStandardScaler()\n",
    "            foo.fit(y_edge_attr)\n",
    "            y_edge_attr=foo.transform(y_edge_attr)\n",
    "        new_edge_attr=torch.cat([ new_edge_attr,y_edge_attr], dim=1)\n",
    "        print('source y added')\n",
    "        print(new_edge_attr.shape)\n",
    "    \n",
    "    if differential_cols!=None:\n",
    "        feat_idx= X_train.columns.get_indexer(edge_feat_cols)\n",
    "        diff_edge_attr=data.x[dst][:,feat_idx]-data.x[src][:,feat_idx] # getting the numerical feature differences as an edge feature indexed by source/destination\n",
    "        new_edge_attr=torch.cat([new_edge_attr, diff_edge_attr], dim=1) #adding it to the feature space\n",
    "        print('differencial features added')\n",
    "        \n",
    "    if tot_scaling ==True:\n",
    "        foo = TorchStandardScaler()\n",
    "        foo.fit(new_edge_attr)\n",
    "        new_edge_attr=foo.transform(new_edge_attr)\n",
    "        \n",
    "    data.edge_attr=new_edge_attr\n",
    "    pass\n",
    "         \n",
    "\n",
    "# edge_feat_dim=data.edge_attr.shape[1] #saving the dimensionality of the edge features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0785d41-c7e0-4bc7-bf0f-21dc959e5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"year_built\",\n",
    "        \"year_reno\",\n",
    "        \"grade\",\n",
    "        \"fbsmt_grade\",\n",
    "        \"condition\",\n",
    "        \"stories\",\n",
    "        \"beds\",\n",
    "        \"bath_full\",\n",
    "        \"bath_3qtr\",\n",
    "        \"bath_half\",\n",
    "    ]\n",
    "num_log_features = [\n",
    "    \"land_val\",\n",
    "    \"imp_val\",\n",
    "    \"sqft_lot\",\n",
    "    \"sqft\",\n",
    "    \"sqft_1\",\n",
    "    \"sqft_fbsmt\",\n",
    "    \"garb_sqft\",\n",
    "    \"gara_sqft\",\n",
    "]\n",
    "    \n",
    "edge_feat_cols= num_features+num_log_features\n",
    "\n",
    "# feat_idx=X_train.columns.get_indexer(edge_feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99d5e966-8c2d-4781-8126-26aeb6c6086f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # getting the numerical feature differences as an edge feature indexed by source/destination\n",
    "# new_edge_attr=torch.cat([new_edge_attr, diff_edge_attr], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8166c2de-de52-4da3-a051-54d1ca89f1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ditsance added\n",
      "time added\n",
      "torch.Size([7756285, 2])\n",
      "differencial features added\n"
     ]
    }
   ],
   "source": [
    "\n",
    "add_edge_feature(data,add_distance=True, add_time= True, add_y=False, y_scaling=False,tot_scaling=True, differential_cols=edge_feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6692162-995b-4826-ab89-8c6646232f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_feat_dim=data.edge_attr.shape[1] #saving the dimensionality of the edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd5456b4-0b60-4417-a301-0b5bd7db42c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_feat_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13d4f6d4-3583-42e8-bd82-67fc341aded4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=data.train_mask,\n",
    "    num_neighbors=[5, 5], # the hops in this had an effect on model training and performance \n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    # num_workers=12,\n",
    ")\n",
    "subgraph_loader = NeighborLoader(\n",
    "    copy.copy(data),\n",
    "    input_nodes=None,\n",
    "    num_neighbors=[-1],\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    # num_workers=12,\n",
    ")\n",
    "\n",
    "\n",
    "# Add global node index information.\n",
    "subgraph_loader.data.num_nodes = data.num_nodes\n",
    "subgraph_loader.data.n_id = torch.arange(data.num_nodes)\n",
    "\n",
    "\n",
    "# No need to maintain these features during evaluation:\n",
    "del subgraph_loader.data.x, subgraph_loader.data.y\n",
    "#validate the graph index\n",
    "print(data.validate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26597ccb-2dc3-415e-af8a-e3423c5a92a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self,  x_dim,edge_feat_dim,mha_heads, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        input_size = x_dim\n",
    "\n",
    "\n",
    "        # print('input_size', input_size)\n",
    "        sizes = [input_size] + hidden_channels\n",
    "        # print('sizes', sizes)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        edge_dim=edge_feat_dim\n",
    "        '''\n",
    "        The gnn blocks\n",
    "        '''\n",
    "        self.convs.append(TransformerConv(sizes[0], hidden_channels[0], edge_dim=edge_dim, heads=mha_heads,concat=False))\n",
    "        self.convs.append(TransformerConv(hidden_channels[0], hidden_channels[1], edge_dim=edge_dim))\n",
    "        layers = []\n",
    "        sizes = [hidden_channels[-1] * 1] + [32] + [1]\n",
    "        # print('sizes', sizes)\n",
    "        for i, (n_in, n_out) in enumerate(zip(sizes[:-1], sizes[1:])):\n",
    "            layers.append(nn.Linear(n_in, n_out))\n",
    "            if i + 2 < len(sizes):\n",
    "                layers.append(nn.ReLU())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "        self.num_layers = len(hidden_channels)        \n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        \n",
    "        # x = self._input_layer(x)\n",
    "        # print(x.shape)\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            # print(i, conv)\n",
    "            x= conv(x, edge_index, edge_attr)\n",
    "            if i < len(self.convs) - 1:\n",
    "                x = x.relu_()\n",
    "                # x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.layers(x)\n",
    "\n",
    "\n",
    "        # x = self._to_monotonic(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_monotonic(x):\n",
    "        for i in range(1, x.shape[-1]):\n",
    "            x[:, i] = x[:, i - 1] + F.relu(x[:, i] - x[:, i - 1])\n",
    "        return x\n",
    "\n",
    "\n",
    "    def inference(self, x_all, subgraph_loader):\n",
    "        pbar = tqdm(total=len(subgraph_loader.dataset) * len(self.convs), leave=True,position=0)\n",
    "        pbar.set_description(\"Evaluating\")\n",
    "\n",
    "        # Compute representations of nodes layer by layer, using *all*\n",
    "        # available edges. This leads to faster computation in contrast to\n",
    "        # immediately computing the final representations of each batch.\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            xs = []\n",
    "            atts=[]\n",
    "            # edges=[]\n",
    "            for batch in subgraph_loader:\n",
    "                # batch=batch.to(device)\n",
    "                # batch=batch.cpu()  # this makes the inference calculations done on cpu\n",
    "                x = x_all[batch.n_id.to(x_all.device)].to(device)\n",
    "                \n",
    "                x, att_edge= conv(x, batch.edge_index.to(device), batch.edge_attr.to(device),return_attention_weights=True)\n",
    "                if i < len(self.convs) - 1:\n",
    "                    x = x.relu_()\n",
    "                # xs.append(x[:batch.batch_size].cpu())\n",
    "                xs.append(x[:batch.batch_size].to(device))\n",
    "                att=att_edge[-1] #getting the att values, as the first elemnt is the index again here\n",
    "                atts.append(att.to(device))\n",
    "                pbar.update(batch.batch_size)\n",
    "            x_all = torch.cat(xs, dim=0)\n",
    "            atts= torch.cat(atts, dim=0)\n",
    "\n",
    "        x_all = self.layers(x_all)\n",
    "\n",
    "        # x_all = self._to_monotonic(x_all)\n",
    "\n",
    "        pbar.close()\n",
    "        return x_all, atts #, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "016f279a-a2b4-4e39-97a0-23b101ac2640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36fe27a9-e2d6-428d-ae3b-248cbf8a04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "mha_heads=16\n",
    "x_dim=len(feature_cols)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device=\"cpu\"\n",
    "\n",
    "model = GNN( x_dim,edge_feat_dim,mha_heads, hidden_channels=[256, 32])\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "x = data_x.to(device)\n",
    "y = data_y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ea7b32f-7326-4f37-a742-cae79b5a2556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7756285])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96848e98-8462-47fa-83d0-5cae5aa0a14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (convs): ModuleList(\n",
       "    (0): TransformerConv(47, 256, heads=16)\n",
       "    (1): TransformerConv(256, 32, heads=1)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3de0d35d-09d3-4426-af15-e0e439f4156e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "726913"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "535888fe-d54e-40f2-9399-2766c6588d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(total=train_idx.size(0),position=0, leave=True)\n",
    "    pbar.set_description(f\"Epoch {epoch:02d}\")\n",
    "\n",
    "    # loss_fn = partial(quantile_loss, quantiles=[0.25, 0.5, 0.75], reduction=\"none\")\n",
    "    # update_wrapper(loss_fn, quantile_loss)\n",
    "\n",
    "    total_loss = 0\n",
    "    total_mdape = []\n",
    "    for batch in train_loader:\n",
    "        batch=batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y = batch.y[:batch.batch_size]\n",
    "        # print(device)\n",
    "        out= model(batch.x, batch.edge_index.to(device), batch.edge_attr.to(device))[:batch.batch_size]  #error :Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)\n",
    "        \n",
    "        loss = loss_fn(y, out)\n",
    "        # print(loss)\n",
    "        loss = torch.mean(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        # print('hello')\n",
    "        total_loss += float(loss)\n",
    "        # print('hello')\n",
    "        total_mdape.append(median_absolute_percentage_error(\n",
    "            response_transformer.inverse_transform(out.cpu().detach().numpy()),\n",
    "            response_transformer.inverse_transform(y.squeeze().cpu().detach().numpy()),\n",
    "        ))\n",
    "\n",
    "        pbar.update(batch.batch_size)\n",
    "        # print('hello')\n",
    "    pbar.close()\n",
    "\n",
    "    loss = total_loss / len(train_loader)\n",
    "    approx_mdape = np.mean(total_mdape)\n",
    "\n",
    "    return loss, approx_mdape\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    y_pred , atts= model.inference(data.x.to(device), subgraph_loader)\n",
    "    # print('got y_pred')\n",
    "    y_true = y.cpu()\n",
    "    # y_pred=y_pred.cpu()  \n",
    "    train_mdape = median_absolute_percentage_error(\n",
    "        response_transformer.inverse_transform(y_true[:len(train_idx), 0].cpu().detach().numpy()),\n",
    "        response_transformer.inverse_transform(y_pred[:len(train_idx), 0].cpu().detach().numpy()),\n",
    "    )\n",
    "    # print('hello')\n",
    "    test_mdape = median_absolute_percentage_error(\n",
    "        y_true[len(train_idx):, 0].cpu().detach().numpy(),\n",
    "        response_transformer.inverse_transform(y_pred[len(train_idx):, 0].cpu().detach().numpy()),\n",
    "    )\n",
    "\n",
    "    return train_mdape, test_mdape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc24b3c3-a06f-4b45-8b17-c66c16925cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>city_50%</th>\n",
       "      <th>submarket_count</th>\n",
       "      <th>grade</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>condition</th>\n",
       "      <th>zoning_50%</th>\n",
       "      <th>city_25%</th>\n",
       "      <th>zoning_25%</th>\n",
       "      <th>year_reno</th>\n",
       "      <th>submarket_75%</th>\n",
       "      <th>bath_half</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>zoning_mean</th>\n",
       "      <th>submarket_min</th>\n",
       "      <th>gara_sqft</th>\n",
       "      <th>city_mean</th>\n",
       "      <th>imp_val</th>\n",
       "      <th>sqft_1</th>\n",
       "      <th>city_min</th>\n",
       "      <th>zoning_std</th>\n",
       "      <th>fbsmt_grade</th>\n",
       "      <th>latitude</th>\n",
       "      <th>submarket_mean</th>\n",
       "      <th>submarket_50%</th>\n",
       "      <th>zoning_count</th>\n",
       "      <th>city_std</th>\n",
       "      <th>city_max</th>\n",
       "      <th>submarket_std</th>\n",
       "      <th>submarket_max</th>\n",
       "      <th>stories</th>\n",
       "      <th>zoning_75%</th>\n",
       "      <th>year_cos</th>\n",
       "      <th>bath_3qtr</th>\n",
       "      <th>land_val</th>\n",
       "      <th>submarket_25%</th>\n",
       "      <th>year_built</th>\n",
       "      <th>garb_sqft</th>\n",
       "      <th>sqft</th>\n",
       "      <th>sqft_fbsmt</th>\n",
       "      <th>city_75%</th>\n",
       "      <th>zoning_min</th>\n",
       "      <th>beds</th>\n",
       "      <th>city_count</th>\n",
       "      <th>trans_year</th>\n",
       "      <th>bath_full</th>\n",
       "      <th>zoning_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.970968</td>\n",
       "      <td>0.471282</td>\n",
       "      <td>0.065233</td>\n",
       "      <td>-2.316161</td>\n",
       "      <td>0.244658</td>\n",
       "      <td>0.607246</td>\n",
       "      <td>-0.060246</td>\n",
       "      <td>0.382524</td>\n",
       "      <td>0.136693</td>\n",
       "      <td>-0.195941</td>\n",
       "      <td>1.330566</td>\n",
       "      <td>-0.914161</td>\n",
       "      <td>-0.961205</td>\n",
       "      <td>-0.018141</td>\n",
       "      <td>-1.197239</td>\n",
       "      <td>-1.077061</td>\n",
       "      <td>0.452151</td>\n",
       "      <td>-1.669431</td>\n",
       "      <td>-0.435703</td>\n",
       "      <td>-0.925064</td>\n",
       "      <td>0.406714</td>\n",
       "      <td>-0.804323</td>\n",
       "      <td>-3.073146</td>\n",
       "      <td>1.286467</td>\n",
       "      <td>1.154536</td>\n",
       "      <td>-0.929073</td>\n",
       "      <td>0.681488</td>\n",
       "      <td>0.856149</td>\n",
       "      <td>1.664532</td>\n",
       "      <td>1.381860</td>\n",
       "      <td>-0.993634</td>\n",
       "      <td>-0.026732</td>\n",
       "      <td>1.600180</td>\n",
       "      <td>-0.810841</td>\n",
       "      <td>-1.001175</td>\n",
       "      <td>1.209738</td>\n",
       "      <td>-2.375813</td>\n",
       "      <td>-0.51112</td>\n",
       "      <td>-1.592863</td>\n",
       "      <td>-0.814674</td>\n",
       "      <td>0.451003</td>\n",
       "      <td>0.670759</td>\n",
       "      <td>-1.562769</td>\n",
       "      <td>1.459587</td>\n",
       "      <td>-1.376047</td>\n",
       "      <td>-0.841701</td>\n",
       "      <td>-0.798090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.970968</td>\n",
       "      <td>0.471282</td>\n",
       "      <td>0.037614</td>\n",
       "      <td>-1.452607</td>\n",
       "      <td>0.244658</td>\n",
       "      <td>0.607246</td>\n",
       "      <td>0.640066</td>\n",
       "      <td>0.382524</td>\n",
       "      <td>0.575943</td>\n",
       "      <td>-0.195941</td>\n",
       "      <td>-0.061033</td>\n",
       "      <td>-0.914161</td>\n",
       "      <td>-0.403283</td>\n",
       "      <td>0.673413</td>\n",
       "      <td>0.030640</td>\n",
       "      <td>-1.077061</td>\n",
       "      <td>0.452151</td>\n",
       "      <td>-1.216774</td>\n",
       "      <td>0.019002</td>\n",
       "      <td>-0.925064</td>\n",
       "      <td>0.654463</td>\n",
       "      <td>-0.804323</td>\n",
       "      <td>-3.073147</td>\n",
       "      <td>-0.115717</td>\n",
       "      <td>-0.128158</td>\n",
       "      <td>2.017033</td>\n",
       "      <td>0.681488</td>\n",
       "      <td>0.856149</td>\n",
       "      <td>0.438207</td>\n",
       "      <td>-0.330177</td>\n",
       "      <td>-0.063291</td>\n",
       "      <td>0.724711</td>\n",
       "      <td>1.600180</td>\n",
       "      <td>-0.810841</td>\n",
       "      <td>-2.531141</td>\n",
       "      <td>-0.166455</td>\n",
       "      <td>-1.550394</td>\n",
       "      <td>-0.51112</td>\n",
       "      <td>-0.624242</td>\n",
       "      <td>-0.814674</td>\n",
       "      <td>0.451003</td>\n",
       "      <td>-1.327248</td>\n",
       "      <td>-0.472358</td>\n",
       "      <td>1.459587</td>\n",
       "      <td>-1.376047</td>\n",
       "      <td>0.604881</td>\n",
       "      <td>1.084385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.970968</td>\n",
       "      <td>0.471282</td>\n",
       "      <td>-1.359128</td>\n",
       "      <td>-0.589053</td>\n",
       "      <td>0.412526</td>\n",
       "      <td>-0.742319</td>\n",
       "      <td>0.640066</td>\n",
       "      <td>0.382524</td>\n",
       "      <td>0.575943</td>\n",
       "      <td>-0.195941</td>\n",
       "      <td>-0.197372</td>\n",
       "      <td>-0.914161</td>\n",
       "      <td>-0.376396</td>\n",
       "      <td>0.673413</td>\n",
       "      <td>-1.443954</td>\n",
       "      <td>-1.077061</td>\n",
       "      <td>0.452151</td>\n",
       "      <td>-1.932028</td>\n",
       "      <td>-0.988606</td>\n",
       "      <td>-0.925064</td>\n",
       "      <td>0.654463</td>\n",
       "      <td>-0.804323</td>\n",
       "      <td>-3.073147</td>\n",
       "      <td>-0.293233</td>\n",
       "      <td>-0.258708</td>\n",
       "      <td>2.017033</td>\n",
       "      <td>0.681488</td>\n",
       "      <td>0.856149</td>\n",
       "      <td>0.396997</td>\n",
       "      <td>0.392359</td>\n",
       "      <td>-0.993634</td>\n",
       "      <td>0.724711</td>\n",
       "      <td>1.568843</td>\n",
       "      <td>-0.810841</td>\n",
       "      <td>-2.216219</td>\n",
       "      <td>-0.390569</td>\n",
       "      <td>-1.105937</td>\n",
       "      <td>-0.51112</td>\n",
       "      <td>-2.090963</td>\n",
       "      <td>-0.814674</td>\n",
       "      <td>0.451003</td>\n",
       "      <td>-1.327248</td>\n",
       "      <td>-1.562769</td>\n",
       "      <td>1.459587</td>\n",
       "      <td>-1.376047</td>\n",
       "      <td>-0.841701</td>\n",
       "      <td>1.084385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.970968</td>\n",
       "      <td>0.598153</td>\n",
       "      <td>0.710338</td>\n",
       "      <td>-0.589053</td>\n",
       "      <td>0.244658</td>\n",
       "      <td>-0.742319</td>\n",
       "      <td>-1.679843</td>\n",
       "      <td>0.577832</td>\n",
       "      <td>-1.570644</td>\n",
       "      <td>-0.195941</td>\n",
       "      <td>0.524578</td>\n",
       "      <td>-0.914161</td>\n",
       "      <td>-0.444426</td>\n",
       "      <td>-1.585319</td>\n",
       "      <td>0.362823</td>\n",
       "      <td>0.825369</td>\n",
       "      <td>0.761584</td>\n",
       "      <td>-1.084430</td>\n",
       "      <td>0.040842</td>\n",
       "      <td>0.476657</td>\n",
       "      <td>0.337136</td>\n",
       "      <td>0.304846</td>\n",
       "      <td>-3.073145</td>\n",
       "      <td>0.501995</td>\n",
       "      <td>0.398463</td>\n",
       "      <td>-0.510705</td>\n",
       "      <td>0.657841</td>\n",
       "      <td>0.063111</td>\n",
       "      <td>0.374804</td>\n",
       "      <td>0.280948</td>\n",
       "      <td>-0.993634</td>\n",
       "      <td>-1.795061</td>\n",
       "      <td>1.600180</td>\n",
       "      <td>-0.810841</td>\n",
       "      <td>-0.545919</td>\n",
       "      <td>0.454513</td>\n",
       "      <td>-0.661481</td>\n",
       "      <td>-0.51112</td>\n",
       "      <td>0.439264</td>\n",
       "      <td>1.406602</td>\n",
       "      <td>0.900075</td>\n",
       "      <td>-0.749279</td>\n",
       "      <td>-0.472358</td>\n",
       "      <td>-0.685973</td>\n",
       "      <td>-1.376047</td>\n",
       "      <td>0.604881</td>\n",
       "      <td>0.351481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.970967</td>\n",
       "      <td>-0.792589</td>\n",
       "      <td>0.623535</td>\n",
       "      <td>-2.316161</td>\n",
       "      <td>0.575461</td>\n",
       "      <td>0.607246</td>\n",
       "      <td>0.637120</td>\n",
       "      <td>-0.791136</td>\n",
       "      <td>-0.231405</td>\n",
       "      <td>-0.195941</td>\n",
       "      <td>1.003057</td>\n",
       "      <td>-0.914161</td>\n",
       "      <td>1.021594</td>\n",
       "      <td>0.682998</td>\n",
       "      <td>1.602576</td>\n",
       "      <td>-1.077061</td>\n",
       "      <td>-0.789338</td>\n",
       "      <td>-2.281091</td>\n",
       "      <td>-0.025243</td>\n",
       "      <td>0.056407</td>\n",
       "      <td>4.632662</td>\n",
       "      <td>-0.804323</td>\n",
       "      <td>-3.073147</td>\n",
       "      <td>1.089809</td>\n",
       "      <td>1.095379</td>\n",
       "      <td>-0.957761</td>\n",
       "      <td>-0.424105</td>\n",
       "      <td>-0.377112</td>\n",
       "      <td>0.264125</td>\n",
       "      <td>1.219748</td>\n",
       "      <td>-0.993634</td>\n",
       "      <td>1.367680</td>\n",
       "      <td>1.517121</td>\n",
       "      <td>-0.810841</td>\n",
       "      <td>-1.907637</td>\n",
       "      <td>1.104556</td>\n",
       "      <td>-1.042443</td>\n",
       "      <td>-0.51112</td>\n",
       "      <td>-1.223087</td>\n",
       "      <td>-0.814674</td>\n",
       "      <td>-0.727348</td>\n",
       "      <td>1.056569</td>\n",
       "      <td>-0.472358</td>\n",
       "      <td>-0.661320</td>\n",
       "      <td>-1.376047</td>\n",
       "      <td>-0.841701</td>\n",
       "      <td>-0.300643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130512</th>\n",
       "      <td>0.255357</td>\n",
       "      <td>3.290538</td>\n",
       "      <td>-1.678721</td>\n",
       "      <td>1.138056</td>\n",
       "      <td>0.244658</td>\n",
       "      <td>-0.742319</td>\n",
       "      <td>3.173845</td>\n",
       "      <td>3.970381</td>\n",
       "      <td>3.964096</td>\n",
       "      <td>5.122897</td>\n",
       "      <td>3.032193</td>\n",
       "      <td>0.988221</td>\n",
       "      <td>0.401076</td>\n",
       "      <td>2.935283</td>\n",
       "      <td>1.471233</td>\n",
       "      <td>0.909259</td>\n",
       "      <td>2.933695</td>\n",
       "      <td>1.039677</td>\n",
       "      <td>1.022823</td>\n",
       "      <td>3.862340</td>\n",
       "      <td>-2.670337</td>\n",
       "      <td>1.414014</td>\n",
       "      <td>0.404468</td>\n",
       "      <td>2.909671</td>\n",
       "      <td>2.984032</td>\n",
       "      <td>-0.958558</td>\n",
       "      <td>-3.257535</td>\n",
       "      <td>-0.948167</td>\n",
       "      <td>3.461845</td>\n",
       "      <td>2.569939</td>\n",
       "      <td>1.797395</td>\n",
       "      <td>2.141852</td>\n",
       "      <td>1.600180</td>\n",
       "      <td>-0.810841</td>\n",
       "      <td>2.680359</td>\n",
       "      <td>2.710581</td>\n",
       "      <td>-1.963103</td>\n",
       "      <td>-0.51112</td>\n",
       "      <td>1.728068</td>\n",
       "      <td>1.517452</td>\n",
       "      <td>2.329244</td>\n",
       "      <td>3.674740</td>\n",
       "      <td>0.618053</td>\n",
       "      <td>-1.063417</td>\n",
       "      <td>1.414804</td>\n",
       "      <td>2.051463</td>\n",
       "      <td>-0.636837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130513</th>\n",
       "      <td>0.219978</td>\n",
       "      <td>-0.360509</td>\n",
       "      <td>-1.741850</td>\n",
       "      <td>0.274502</td>\n",
       "      <td>0.244658</td>\n",
       "      <td>-0.742319</td>\n",
       "      <td>-0.378814</td>\n",
       "      <td>-0.528058</td>\n",
       "      <td>-0.466610</td>\n",
       "      <td>5.130852</td>\n",
       "      <td>-1.329721</td>\n",
       "      <td>-0.914161</td>\n",
       "      <td>0.070056</td>\n",
       "      <td>-0.338054</td>\n",
       "      <td>-0.730929</td>\n",
       "      <td>1.055759</td>\n",
       "      <td>-0.261775</td>\n",
       "      <td>0.882768</td>\n",
       "      <td>0.147340</td>\n",
       "      <td>-0.716128</td>\n",
       "      <td>0.065684</td>\n",
       "      <td>1.414014</td>\n",
       "      <td>0.058652</td>\n",
       "      <td>-1.415599</td>\n",
       "      <td>-1.368311</td>\n",
       "      <td>0.993825</td>\n",
       "      <td>1.180401</td>\n",
       "      <td>0.739372</td>\n",
       "      <td>-0.349595</td>\n",
       "      <td>-2.132841</td>\n",
       "      <td>0.867052</td>\n",
       "      <td>-0.166248</td>\n",
       "      <td>1.600180</td>\n",
       "      <td>2.254919</td>\n",
       "      <td>0.436039</td>\n",
       "      <td>-1.457073</td>\n",
       "      <td>-0.756721</td>\n",
       "      <td>-0.51112</td>\n",
       "      <td>1.337556</td>\n",
       "      <td>1.321629</td>\n",
       "      <td>0.024395</td>\n",
       "      <td>-0.456304</td>\n",
       "      <td>1.708464</td>\n",
       "      <td>0.188015</td>\n",
       "      <td>1.414804</td>\n",
       "      <td>0.604881</td>\n",
       "      <td>0.605745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130514</th>\n",
       "      <td>0.108517</td>\n",
       "      <td>0.471282</td>\n",
       "      <td>0.037614</td>\n",
       "      <td>0.274502</td>\n",
       "      <td>0.244658</td>\n",
       "      <td>-0.742319</td>\n",
       "      <td>0.640066</td>\n",
       "      <td>0.382524</td>\n",
       "      <td>0.575943</td>\n",
       "      <td>5.138806</td>\n",
       "      <td>-0.061033</td>\n",
       "      <td>-0.914161</td>\n",
       "      <td>-0.210339</td>\n",
       "      <td>0.673413</td>\n",
       "      <td>0.030640</td>\n",
       "      <td>-1.077061</td>\n",
       "      <td>0.452151</td>\n",
       "      <td>1.172978</td>\n",
       "      <td>0.551883</td>\n",
       "      <td>-0.925064</td>\n",
       "      <td>0.654463</td>\n",
       "      <td>1.136722</td>\n",
       "      <td>0.263746</td>\n",
       "      <td>-0.115717</td>\n",
       "      <td>-0.128158</td>\n",
       "      <td>2.017033</td>\n",
       "      <td>0.681488</td>\n",
       "      <td>0.856149</td>\n",
       "      <td>0.438207</td>\n",
       "      <td>-0.330177</td>\n",
       "      <td>0.867052</td>\n",
       "      <td>0.724711</td>\n",
       "      <td>1.600180</td>\n",
       "      <td>0.722039</td>\n",
       "      <td>0.436039</td>\n",
       "      <td>-0.166455</td>\n",
       "      <td>-0.724974</td>\n",
       "      <td>-0.51112</td>\n",
       "      <td>1.624731</td>\n",
       "      <td>1.460241</td>\n",
       "      <td>0.451003</td>\n",
       "      <td>-1.327248</td>\n",
       "      <td>0.618053</td>\n",
       "      <td>1.459587</td>\n",
       "      <td>1.414804</td>\n",
       "      <td>0.604881</td>\n",
       "      <td>1.084385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130515</th>\n",
       "      <td>0.105787</td>\n",
       "      <td>0.471282</td>\n",
       "      <td>0.664963</td>\n",
       "      <td>-0.589053</td>\n",
       "      <td>0.244658</td>\n",
       "      <td>-0.742319</td>\n",
       "      <td>-0.255321</td>\n",
       "      <td>0.382524</td>\n",
       "      <td>-0.331072</td>\n",
       "      <td>5.157366</td>\n",
       "      <td>0.343515</td>\n",
       "      <td>-0.914161</td>\n",
       "      <td>-0.662110</td>\n",
       "      <td>-0.345248</td>\n",
       "      <td>1.426945</td>\n",
       "      <td>-1.077061</td>\n",
       "      <td>0.452151</td>\n",
       "      <td>-0.836838</td>\n",
       "      <td>-0.488606</td>\n",
       "      <td>-0.925064</td>\n",
       "      <td>-0.123962</td>\n",
       "      <td>1.136722</td>\n",
       "      <td>0.855969</td>\n",
       "      <td>0.464629</td>\n",
       "      <td>0.523134</td>\n",
       "      <td>-0.772085</td>\n",
       "      <td>0.681488</td>\n",
       "      <td>0.856149</td>\n",
       "      <td>-0.853896</td>\n",
       "      <td>0.593828</td>\n",
       "      <td>-0.993634</td>\n",
       "      <td>-0.281518</td>\n",
       "      <td>1.600180</td>\n",
       "      <td>0.722039</td>\n",
       "      <td>0.450687</td>\n",
       "      <td>0.610207</td>\n",
       "      <td>-1.105937</td>\n",
       "      <td>-0.51112</td>\n",
       "      <td>-0.037931</td>\n",
       "      <td>1.341873</td>\n",
       "      <td>0.451003</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>-0.472358</td>\n",
       "      <td>1.459587</td>\n",
       "      <td>1.414804</td>\n",
       "      <td>-0.841701</td>\n",
       "      <td>-0.738392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130516</th>\n",
       "      <td>0.152664</td>\n",
       "      <td>0.471282</td>\n",
       "      <td>0.664963</td>\n",
       "      <td>-0.589053</td>\n",
       "      <td>-0.862869</td>\n",
       "      <td>-0.742319</td>\n",
       "      <td>0.786474</td>\n",
       "      <td>0.382524</td>\n",
       "      <td>1.113400</td>\n",
       "      <td>5.106989</td>\n",
       "      <td>0.343515</td>\n",
       "      <td>0.988221</td>\n",
       "      <td>-1.436375</td>\n",
       "      <td>0.836760</td>\n",
       "      <td>1.426945</td>\n",
       "      <td>-1.077061</td>\n",
       "      <td>0.452151</td>\n",
       "      <td>0.310325</td>\n",
       "      <td>-0.383868</td>\n",
       "      <td>-0.925064</td>\n",
       "      <td>-0.487334</td>\n",
       "      <td>-0.804323</td>\n",
       "      <td>0.812625</td>\n",
       "      <td>0.464629</td>\n",
       "      <td>0.523134</td>\n",
       "      <td>-0.945807</td>\n",
       "      <td>0.681488</td>\n",
       "      <td>0.856149</td>\n",
       "      <td>-0.853896</td>\n",
       "      <td>0.593828</td>\n",
       "      <td>-0.063291</td>\n",
       "      <td>0.408961</td>\n",
       "      <td>1.248613</td>\n",
       "      <td>-0.810841</td>\n",
       "      <td>-0.536338</td>\n",
       "      <td>0.610207</td>\n",
       "      <td>-1.613888</td>\n",
       "      <td>-0.51112</td>\n",
       "      <td>-0.939643</td>\n",
       "      <td>-0.814674</td>\n",
       "      <td>0.451003</td>\n",
       "      <td>1.918386</td>\n",
       "      <td>-1.562769</td>\n",
       "      <td>1.459587</td>\n",
       "      <td>1.414804</td>\n",
       "      <td>-0.841701</td>\n",
       "      <td>-0.523119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130517 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        longitude  city_50%  submarket_count     grade  year_sin  condition  \\\n",
       "0       -3.970968  0.471282         0.065233 -2.316161  0.244658   0.607246   \n",
       "1       -3.970968  0.471282         0.037614 -1.452607  0.244658   0.607246   \n",
       "2       -3.970968  0.471282        -1.359128 -0.589053  0.412526  -0.742319   \n",
       "3       -3.970968  0.598153         0.710338 -0.589053  0.244658  -0.742319   \n",
       "4       -3.970967 -0.792589         0.623535 -2.316161  0.575461   0.607246   \n",
       "...           ...       ...              ...       ...       ...        ...   \n",
       "130512   0.255357  3.290538        -1.678721  1.138056  0.244658  -0.742319   \n",
       "130513   0.219978 -0.360509        -1.741850  0.274502  0.244658  -0.742319   \n",
       "130514   0.108517  0.471282         0.037614  0.274502  0.244658  -0.742319   \n",
       "130515   0.105787  0.471282         0.664963 -0.589053  0.244658  -0.742319   \n",
       "130516   0.152664  0.471282         0.664963 -0.589053 -0.862869  -0.742319   \n",
       "\n",
       "        zoning_50%  city_25%  zoning_25%  year_reno  submarket_75%  bath_half  \\\n",
       "0        -0.060246  0.382524    0.136693  -0.195941       1.330566  -0.914161   \n",
       "1         0.640066  0.382524    0.575943  -0.195941      -0.061033  -0.914161   \n",
       "2         0.640066  0.382524    0.575943  -0.195941      -0.197372  -0.914161   \n",
       "3        -1.679843  0.577832   -1.570644  -0.195941       0.524578  -0.914161   \n",
       "4         0.637120 -0.791136   -0.231405  -0.195941       1.003057  -0.914161   \n",
       "...            ...       ...         ...        ...            ...        ...   \n",
       "130512    3.173845  3.970381    3.964096   5.122897       3.032193   0.988221   \n",
       "130513   -0.378814 -0.528058   -0.466610   5.130852      -1.329721  -0.914161   \n",
       "130514    0.640066  0.382524    0.575943   5.138806      -0.061033  -0.914161   \n",
       "130515   -0.255321  0.382524   -0.331072   5.157366       0.343515  -0.914161   \n",
       "130516    0.786474  0.382524    1.113400   5.106989       0.343515   0.988221   \n",
       "\n",
       "        sqft_lot  zoning_mean  submarket_min  gara_sqft  city_mean   imp_val  \\\n",
       "0      -0.961205    -0.018141      -1.197239  -1.077061   0.452151 -1.669431   \n",
       "1      -0.403283     0.673413       0.030640  -1.077061   0.452151 -1.216774   \n",
       "2      -0.376396     0.673413      -1.443954  -1.077061   0.452151 -1.932028   \n",
       "3      -0.444426    -1.585319       0.362823   0.825369   0.761584 -1.084430   \n",
       "4       1.021594     0.682998       1.602576  -1.077061  -0.789338 -2.281091   \n",
       "...          ...          ...            ...        ...        ...       ...   \n",
       "130512  0.401076     2.935283       1.471233   0.909259   2.933695  1.039677   \n",
       "130513  0.070056    -0.338054      -0.730929   1.055759  -0.261775  0.882768   \n",
       "130514 -0.210339     0.673413       0.030640  -1.077061   0.452151  1.172978   \n",
       "130515 -0.662110    -0.345248       1.426945  -1.077061   0.452151 -0.836838   \n",
       "130516 -1.436375     0.836760       1.426945  -1.077061   0.452151  0.310325   \n",
       "\n",
       "          sqft_1  city_min  zoning_std  fbsmt_grade  latitude  submarket_mean  \\\n",
       "0      -0.435703 -0.925064    0.406714    -0.804323 -3.073146        1.286467   \n",
       "1       0.019002 -0.925064    0.654463    -0.804323 -3.073147       -0.115717   \n",
       "2      -0.988606 -0.925064    0.654463    -0.804323 -3.073147       -0.293233   \n",
       "3       0.040842  0.476657    0.337136     0.304846 -3.073145        0.501995   \n",
       "4      -0.025243  0.056407    4.632662    -0.804323 -3.073147        1.089809   \n",
       "...          ...       ...         ...          ...       ...             ...   \n",
       "130512  1.022823  3.862340   -2.670337     1.414014  0.404468        2.909671   \n",
       "130513  0.147340 -0.716128    0.065684     1.414014  0.058652       -1.415599   \n",
       "130514  0.551883 -0.925064    0.654463     1.136722  0.263746       -0.115717   \n",
       "130515 -0.488606 -0.925064   -0.123962     1.136722  0.855969        0.464629   \n",
       "130516 -0.383868 -0.925064   -0.487334    -0.804323  0.812625        0.464629   \n",
       "\n",
       "        submarket_50%  zoning_count  city_std  city_max  submarket_std  \\\n",
       "0            1.154536     -0.929073  0.681488  0.856149       1.664532   \n",
       "1           -0.128158      2.017033  0.681488  0.856149       0.438207   \n",
       "2           -0.258708      2.017033  0.681488  0.856149       0.396997   \n",
       "3            0.398463     -0.510705  0.657841  0.063111       0.374804   \n",
       "4            1.095379     -0.957761 -0.424105 -0.377112       0.264125   \n",
       "...               ...           ...       ...       ...            ...   \n",
       "130512       2.984032     -0.958558 -3.257535 -0.948167       3.461845   \n",
       "130513      -1.368311      0.993825  1.180401  0.739372      -0.349595   \n",
       "130514      -0.128158      2.017033  0.681488  0.856149       0.438207   \n",
       "130515       0.523134     -0.772085  0.681488  0.856149      -0.853896   \n",
       "130516       0.523134     -0.945807  0.681488  0.856149      -0.853896   \n",
       "\n",
       "        submarket_max   stories  zoning_75%  year_cos  bath_3qtr  land_val  \\\n",
       "0            1.381860 -0.993634   -0.026732  1.600180  -0.810841 -1.001175   \n",
       "1           -0.330177 -0.063291    0.724711  1.600180  -0.810841 -2.531141   \n",
       "2            0.392359 -0.993634    0.724711  1.568843  -0.810841 -2.216219   \n",
       "3            0.280948 -0.993634   -1.795061  1.600180  -0.810841 -0.545919   \n",
       "4            1.219748 -0.993634    1.367680  1.517121  -0.810841 -1.907637   \n",
       "...               ...       ...         ...       ...        ...       ...   \n",
       "130512       2.569939  1.797395    2.141852  1.600180  -0.810841  2.680359   \n",
       "130513      -2.132841  0.867052   -0.166248  1.600180   2.254919  0.436039   \n",
       "130514      -0.330177  0.867052    0.724711  1.600180   0.722039  0.436039   \n",
       "130515       0.593828 -0.993634   -0.281518  1.600180   0.722039  0.450687   \n",
       "130516       0.593828 -0.063291    0.408961  1.248613  -0.810841 -0.536338   \n",
       "\n",
       "        submarket_25%  year_built  garb_sqft      sqft  sqft_fbsmt  city_75%  \\\n",
       "0            1.209738   -2.375813   -0.51112 -1.592863   -0.814674  0.451003   \n",
       "1           -0.166455   -1.550394   -0.51112 -0.624242   -0.814674  0.451003   \n",
       "2           -0.390569   -1.105937   -0.51112 -2.090963   -0.814674  0.451003   \n",
       "3            0.454513   -0.661481   -0.51112  0.439264    1.406602  0.900075   \n",
       "4            1.104556   -1.042443   -0.51112 -1.223087   -0.814674 -0.727348   \n",
       "...               ...         ...        ...       ...         ...       ...   \n",
       "130512       2.710581   -1.963103   -0.51112  1.728068    1.517452  2.329244   \n",
       "130513      -1.457073   -0.756721   -0.51112  1.337556    1.321629  0.024395   \n",
       "130514      -0.166455   -0.724974   -0.51112  1.624731    1.460241  0.451003   \n",
       "130515       0.610207   -1.105937   -0.51112 -0.037931    1.341873  0.451003   \n",
       "130516       0.610207   -1.613888   -0.51112 -0.939643   -0.814674  0.451003   \n",
       "\n",
       "        zoning_min      beds  city_count  trans_year  bath_full  zoning_max  \n",
       "0         0.670759 -1.562769    1.459587   -1.376047  -0.841701   -0.798090  \n",
       "1        -1.327248 -0.472358    1.459587   -1.376047   0.604881    1.084385  \n",
       "2        -1.327248 -1.562769    1.459587   -1.376047  -0.841701    1.084385  \n",
       "3        -0.749279 -0.472358   -0.685973   -1.376047   0.604881    0.351481  \n",
       "4         1.056569 -0.472358   -0.661320   -1.376047  -0.841701   -0.300643  \n",
       "...            ...       ...         ...         ...        ...         ...  \n",
       "130512    3.674740  0.618053   -1.063417    1.414804   2.051463   -0.636837  \n",
       "130513   -0.456304  1.708464    0.188015    1.414804   0.604881    0.605745  \n",
       "130514   -1.327248  0.618053    1.459587    1.414804   0.604881    1.084385  \n",
       "130515    0.006942 -0.472358    1.459587    1.414804  -0.841701   -0.738392  \n",
       "130516    1.918386 -1.562769    1.459587    1.414804  -0.841701   -0.523119  \n",
       "\n",
       "[130517 rows x 47 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79848491-eb4c-41ff-891a-6d765b70cfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 00:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01: 100%|██████████| 130517/130517 [01:25<00:00, 1527.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Loss: 0.0335, Approx. Train: 0.4395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:19<00:00, 4070.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0729, Test: 0.1457\n",
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|██████████| 130517/130517 [01:26<00:00, 1500.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02, Loss: 0.0274, Approx. Train: 0.4411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:18<00:00, 4139.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0771, Test: 0.1337\n",
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: 100%|██████████| 130517/130517 [01:28<00:00, 1474.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03, Loss: 0.0261, Approx. Train: 0.4414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:16<00:00, 4200.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0675, Test: 0.1601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: 100%|██████████| 130517/130517 [01:39<00:00, 1318.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04, Loss: 0.0254, Approx. Train: 0.4417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:16<00:00, 4196.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0673, Test: 0.1285\n",
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06: 100%|██████████| 130517/130517 [01:34<00:00, 1375.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06, Loss: 0.0244, Approx. Train: 0.4417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:20<00:00, 4015.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0645, Test: 0.1222\n",
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07: 100%|██████████| 130517/130517 [01:30<00:00, 1435.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07, Loss: 0.0241, Approx. Train: 0.4419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:16<00:00, 4206.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0673, Test: 0.1262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08: 100%|██████████| 130517/130517 [01:33<00:00, 1398.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08, Loss: 0.0237, Approx. Train: 0.4417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:23<00:00, 3883.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0681, Test: 0.1042\n",
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09: 100%|██████████| 130517/130517 [01:30<00:00, 1438.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09, Loss: 0.0234, Approx. Train: 0.4421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:16<00:00, 4207.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0624, Test: 0.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 130517/130517 [01:32<00:00, 1418.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0231, Approx. Train: 0.4421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:16<00:00, 4198.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0635, Test: 0.1057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 130517/130517 [01:31<00:00, 1422.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.0227, Approx. Train: 0.4421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:16<00:00, 4229.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0635, Test: 0.1045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 130517/130517 [01:32<00:00, 1418.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.0226, Approx. Train: 0.4420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:22<00:00, 3907.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0644, Test: 0.1171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 130517/130517 [01:40<00:00, 1295.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.0223, Approx. Train: 0.4423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:20<00:00, 3988.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0633, Test: 0.1023\n",
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 130517/130517 [01:33<00:00, 1401.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.0220, Approx. Train: 0.4422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:17<00:00, 4162.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0619, Test: 0.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 130517/130517 [01:31<00:00, 1431.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.0217, Approx. Train: 0.4424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:17<00:00, 4193.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0652, Test: 0.1090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 130517/130517 [01:41<00:00, 1289.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.0216, Approx. Train: 0.4424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:18<00:00, 4132.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0634, Test: 0.1134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 130517/130517 [01:35<00:00, 1361.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.0213, Approx. Train: 0.4425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:18<00:00, 4140.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0623, Test: 0.1115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 130517/130517 [01:38<00:00, 1330.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.0212, Approx. Train: 0.4425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:20<00:00, 3994.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0610, Test: 0.1058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 130517/130517 [01:39<00:00, 1307.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.0208, Approx. Train: 0.4427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:17<00:00, 4185.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0608, Test: 0.1135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 130517/130517 [01:39<00:00, 1312.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.0208, Approx. Train: 0.4426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:21<00:00, 3960.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0597, Test: 0.1139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 130517/130517 [01:36<00:00, 1358.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 0.0205, Approx. Train: 0.4426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:21<00:00, 3973.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0609, Test: 0.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 130517/130517 [01:34<00:00, 1382.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 0.0205, Approx. Train: 0.4426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:19<00:00, 4077.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0604, Test: 0.1081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 130517/130517 [01:45<00:00, 1235.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 0.0203, Approx. Train: 0.4427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:18<00:00, 4140.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0603, Test: 0.1170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 130517/130517 [01:40<00:00, 1301.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 0.0200, Approx. Train: 0.4427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 323024/323024 [01:23<00:00, 3859.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0608, Test: 0.1146\n",
      "Early Stopping Initiated...Loading the best Weights\n"
     ]
    }
   ],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_epochs = 50\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "test_accs = []\n",
    "for run in range(1):\n",
    "    print(f\"Run {run:02d}:\")\n",
    "    early_stopper = EarlyStopper(patience=12, min_delta=0)\n",
    "    model.reset_parameters()\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [\n",
    "            \n",
    "            {\"params\": model.convs.parameters()},\n",
    "            {\"params\": model.layers.parameters()},\n",
    "        ],\n",
    "        # lr=1e-5,\n",
    "        # eps=1e-4\n",
    "        lr=1e-3,\n",
    "    )\n",
    "    best_mdape=1000000\n",
    "    best_val_acc = final_test_acc = 0\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss, acc = train(epoch)\n",
    "        print(f\"Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train: {acc:.4f}\")\n",
    " \n",
    "        if epoch >= 1:   \n",
    "            # print('hello')\n",
    "            train_mdape, test_mdape = test()\n",
    "            print(f\"Train: {train_mdape:.4f}, Test: {test_mdape:.4f}\")\n",
    "            if test_mdape<=best_mdape:\n",
    "                best_mdape=test_mdape\n",
    "                print('saving model')\n",
    "                torch.save(model, f'model_best_v{version}.pt')\n",
    "            if early_stopper.early_stop(test_mdape):\n",
    "                print('Early Stopping Initiated...Loading the best Weights')\n",
    "                # checkpoint = torch.load('model_best.pt')\n",
    "                model=torch.load(f'model_best_v{version}.pt')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55b8099c-2de3-4850-9fb9-fe2e32dcc156",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data,f'data_v{version}')\n",
    "import pickle \n",
    "X_train.to_parquet(f'X_train_v{version}.gzip')\n",
    "# with open(f'feature_dict_v{version}.pkl', 'wb') as f:\n",
    "#     pickle.dump(feature_dict_, f)\n",
    "torch.save(train_idx, f'train_idx_v{version}.pt')\n",
    "with open(f'response_transformer_v{version}.pkl', 'wb') as f:\n",
    "    pickle.dump(response_transformer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab68d7d6-2297-4aa8-a801-c0d0a29f871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def gnn_pred():\n",
    "    model.eval()\n",
    "\n",
    "    y_pred , atts= model.inference(data.x.to(device), subgraph_loader)\n",
    "    return y_pred, atts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213bf1ae-3af3-440a-9c30-b2e76f3dfa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|          | 3360/323024 [00:00<01:06, 4841.07it/s]"
     ]
    }
   ],
   "source": [
    "y_pred , atts=gnn_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351bd98a-8bd1-4fc3-b739-c56feea68e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_all=torch.from_numpy(df_1[response_col].values)\n",
    "y_pred_test=response_transformer.inverse_transform(y_pred[len(train_idx):, 0].cpu().detach().numpy())\n",
    "                                                   \n",
    "                                                   \n",
    "y_true = y.cpu()\n",
    "y_test= y_true[len(train_idx):, 0].cpu().detach().numpy()\n",
    "# y_pred_1= [np.array(x) for x in list(zip(*y_pred_test[:, [1, 0, 2]].tolist()))]\n",
    "results = pd.DataFrame([evaluate_preds(y_test, y_pred_test.flatten())], index=[f\"GNN_v{version}\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "395d5fd7-f602-4229-8e6c-a958541dd3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kc_gnn_16'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ccfbee3-08cc-49a5-99a6-2d6e2b23cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(f'kc_exp_results_{version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c554fe24-5f42-4823-98dc-aa6df651b5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30% 0.9063719954831424\n",
      "10% 0.5283110179061139\n"
     ]
    }
   ],
   "source": [
    "df_new=df_test.copy()\n",
    "# df_new['recordingdate']=pd.to_datetime(df_new['recordingdate'])\n",
    "# df_new['week_period']=df_new['recordingdate'].dt.to_period('w')\n",
    "df_new['y_pred']=y_pred_test.flatten()\n",
    "df_new['indive_mape']=np.abs(df_new['y_pred'].values-df_new[response_col].values)/df_new[response_col].values\n",
    "print('30%', len(df_new.loc[df_new['indive_mape']<=0.3])/len(df_new))\n",
    "print('10%', len(df_new.loc[df_new['indive_mape']<=0.1])/len(df_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38c6346c-0c5a-49a4-ab87-b582be98a497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_new['indive_mape'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d88d611b-c75c-40f6-9de6-d0212039f716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 5802868])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_all=y_all=pd.concat([df_train, df_test])[response_col].values\n",
    "all_idx=np.arange(0, len(y_all))\n",
    "pred_dic= dict(zip(all_idx, response_transformer.inverse_transform(y_pred.cpu().detach().numpy()).flatten()))\n",
    "true_dic=dict(zip(all_idx, y_all))\n",
    "distance=data.edge_attr.cpu()\n",
    "edge_index_att= torch.cat([data.edge_index.cpu(), torch.t(atts.cpu())], dim=0)\n",
    "edge_index_att= torch.cat([edge_index_att, torch.t(distance)], dim=0)\n",
    "print(edge_index_att.shape)\n",
    "test_edge_index=edge_index_att[:,edge_index_att[1]>train_idx[-1]]\n",
    "\n",
    "df_con=df_con= pd.DataFrame({'source':test_edge_index[0].detach().numpy(),\n",
    "                      'target':test_edge_index[1].detach().numpy(),\n",
    "                            'att': test_edge_index[2].detach().numpy(),\n",
    "                           'distance':test_edge_index[3].detach().numpy() })\n",
    "df_con['source_pred']=df_con['source'].map(pred_dic)\n",
    "df_con['target_pred']=df_con['target'].map(pred_dic)\n",
    "df_con['pred_diff']=abs(df_con['target_pred']-df_con['source_pred'])\n",
    "df_con['target_true']=df_con['target'].map(true_dic)\n",
    "df_con['source_true']=df_con['source'].map(true_dic)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a2cd6-9f7c-4016-9935-9d99d0e4db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con.groupby('target').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a81cf00-90d9-4241-85ab-713a5be6818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(df_con,n=5, sort_method= 'pred_diff',aggr='mean', source_metric='pred',hard_n_cut_off=False):\n",
    "    '''\n",
    "    this function gets the comps and evaluate its performance.\n",
    "    args: \n",
    "    df_con: dataframe containing the source target ids, predictions, true values, and attention values \n",
    "    n: number of comps\n",
    "    sort_method: ranking mechanism where pred_diff sorts by abs prediction differences between the neighbors and the target, and attention ranks solely based on attention\n",
    "    aggr: aggregation method of the top n comps : mean, median, att_weighted\n",
    "    source_metric: true means calculated metric with y_true of comps, pred means calculate metric based on y_pred of comps\n",
    "    hard_n_cutt_off: remove \n",
    "    '''\n",
    "    if sort_method == 'pred_diff':\n",
    "        df_con=df_con.sort_values(['target', 'pred_diff'])\n",
    "        top_n_df=df_con.groupby('target').head(n)\n",
    "        \n",
    "    if sort_method=='attention':\n",
    "        df_con=df_con.sort_values(['target', 'att'])\n",
    "        top_n_df=df_con.groupby('target').head(n)\n",
    "    if hard_n_cut_off==True: #this removes the nodes that have less than n source neighbors\n",
    "        n_count=dict(zip(df_con.groupby('target').size().reset_index()['target'].values,\n",
    "                df_con.groupby('target').size().reset_index()[0].values))\n",
    "        \n",
    "        top_n_df['n_count']=top_n_df['target'].map(n_count)\n",
    "        # print(len)\n",
    "        top_n_df=top_n_df.loc[top_n_df['n_count']>=n]\n",
    "        # print(len(top_n_df))\n",
    "    mean_distance=top_n_df['distance'].mean()\n",
    "    median_distance=top_n_df['distance'].median()\n",
    "    print(f'neighbor distance average in km: {mean_distance}')\n",
    "    print(f'neighbor distance median in km: {median_distance}')\n",
    "    if aggr=='mean':\n",
    "        agg_df=top_n_df[['target', 'source_pred','source_true', 'target_pred', 'target_true']].groupby('target').mean()\n",
    "    \n",
    "    if aggr=='median':\n",
    "        agg_df=top_n_df[['target', 'source_pred','source_true', 'target_pred', 'target_true']].groupby('target').median()\n",
    "    # out= pd.DataFrame([evaluate_preds(agg_df['target_true'].values, *y_pred_1)], index=[\"comps\"])\n",
    "    \n",
    "    if aggr=='att_weighted':\n",
    "        # group=top_n_df.groupby('target').sum()\n",
    "        # print(group.loc[group['att']==0])\n",
    "        if source_metric=='pred':\n",
    "            top_n_df['att']=top_n_df['att']+0.000001\n",
    "            agg_df=top_n_df[['target', 'source_pred', 'target_pred', 'target_true','att']].groupby(['target']).apply(\n",
    "                lambda x: pd.Series([\n",
    "                    np.mean(x['target_true']),\n",
    "                    np.average(x['source_pred'], weights=x['att'])\n",
    "                ], index=['target_true', 'source_pred'])\n",
    "            )\n",
    "        if source_metric=='true':\n",
    "            top_n_df['att']=top_n_df['att']+0.000001\n",
    "            agg_df=top_n_df[['target', 'source_pred','source_true', 'target_pred', 'target_true','att']].groupby(['target']).apply(\n",
    "                lambda x: pd.Series([\n",
    "                    np.mean(x['target_true']),\n",
    "                    np.average(x['source_true'], weights=x['att'])\n",
    "                ], index=['target_true', 'source_true'])\n",
    "            )\n",
    "    if source_metric=='pred':\n",
    "        out= pd.DataFrame([evaluate_preds(agg_df['target_true'].values,agg_df['source_pred'].values)], index=[\"comps\"])\n",
    "\n",
    "\n",
    "    if source_metric=='true':\n",
    "        out= pd.DataFrame([evaluate_preds(agg_df['target_true'].values,agg_df['source_true'].values)], index=[\"comps\"])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5536511-6537-4bd4-b21a-684fe26de16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_149/2641838427.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_n_df['n_count']=top_n_df['target'].map(n_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbor distance average in km: 0.5718359351158142\n",
      "neighbor distance median in km: 0.5947365760803223\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MdAE</th>\n",
       "      <th>MPE</th>\n",
       "      <th>MdPE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MdAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comps</th>\n",
       "      <td>30492</td>\n",
       "      <td>-1.119966</td>\n",
       "      <td>800662.409521</td>\n",
       "      <td>583454.403253</td>\n",
       "      <td>0.878116</td>\n",
       "      <td>0.540088</td>\n",
       "      <td>1.0317</td>\n",
       "      <td>0.600684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Count        R2            MAE           MdAE       MPE      MdPE  \\\n",
       "comps  30492 -1.119966  800662.409521  583454.403253  0.878116  0.540088   \n",
       "\n",
       "         MAPE     MdAPE  \n",
       "comps  1.0317  0.600684  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n(df_con,n=5, sort_method='attention', aggr='att_weighted', source_metric='true', hard_n_cut_off=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27fddf0e-4e45-4d2d-baf8-815fdb04dc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_149/2641838427.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_n_df['n_count']=top_n_df['target'].map(n_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbor distance average in km: 0.5974395275115967\n",
      "neighbor distance median in km: 0.62982177734375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MdAE</th>\n",
       "      <th>MPE</th>\n",
       "      <th>MdPE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MdAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comps</th>\n",
       "      <td>30492</td>\n",
       "      <td>0.45722</td>\n",
       "      <td>225906.691218</td>\n",
       "      <td>99899.051341</td>\n",
       "      <td>-0.031963</td>\n",
       "      <td>-0.051058</td>\n",
       "      <td>0.178107</td>\n",
       "      <td>0.125998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Count       R2            MAE          MdAE       MPE      MdPE  \\\n",
       "comps  30492  0.45722  225906.691218  99899.051341 -0.031963 -0.051058   \n",
       "\n",
       "           MAPE     MdAPE  \n",
       "comps  0.178107  0.125998  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n(df_con,n=5, sort_method='pred_diff', aggr='att_weighted', source_metric='true', hard_n_cut_off=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64b04211-8b31-4ad9-a373-7b9c46717eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbor distance average in km: 0.5974395275115967\n",
      "neighbor distance median in km: 0.62982177734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_149/2641838427.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_n_df['n_count']=top_n_df['target'].map(n_count)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MdAE</th>\n",
       "      <th>MPE</th>\n",
       "      <th>MdPE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MdAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comps</th>\n",
       "      <td>30492</td>\n",
       "      <td>0.51543</td>\n",
       "      <td>205247.871986</td>\n",
       "      <td>93990.0</td>\n",
       "      <td>-0.01798</td>\n",
       "      <td>-0.041948</td>\n",
       "      <td>0.16605</td>\n",
       "      <td>0.116294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Count       R2            MAE     MdAE      MPE      MdPE     MAPE  \\\n",
       "comps  30492  0.51543  205247.871986  93990.0 -0.01798 -0.041948  0.16605   \n",
       "\n",
       "          MdAPE  \n",
       "comps  0.116294  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n(df_con,n=5, sort_method='pred_diff', aggr='mean', source_metric='true', hard_n_cut_off=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54d9cea8-6e5f-4eed-a163-ead6c46bdf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbor distance average in km: 0.5974395275115967\n",
      "neighbor distance median in km: 0.62982177734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_149/2641838427.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_n_df['n_count']=top_n_df['target'].map(n_count)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MdAE</th>\n",
       "      <th>MPE</th>\n",
       "      <th>MdPE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MdAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comps</th>\n",
       "      <td>30492</td>\n",
       "      <td>0.480909</td>\n",
       "      <td>213168.149023</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>-0.028896</td>\n",
       "      <td>-0.049434</td>\n",
       "      <td>0.168431</td>\n",
       "      <td>0.119048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Count        R2            MAE     MdAE       MPE      MdPE      MAPE  \\\n",
       "comps  30492  0.480909  213168.149023  95000.0 -0.028896 -0.049434  0.168431   \n",
       "\n",
       "          MdAPE  \n",
       "comps  0.119048  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n(df_con,n=5, sort_method='pred_diff', aggr='median', source_metric='true', hard_n_cut_off=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe369c8-be89-422f-8767-07529b9c82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df_con['target'].value_counts()\n",
    "_ = plt.hist(df_con['target'].value_counts().values, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(f'{version} link histogram on the test sampel')\n",
    "# Text(0.5, 1.0, \"Connection (to target) Histogram with 'auto' bins\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "torch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
